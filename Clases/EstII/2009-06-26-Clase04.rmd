---
layout: post
title: "Clase 04"
main-class: 'clase'
permalink: /EstadisticaII/EstII:title.html
tags:

introduction: |
              Estadísticos de orden <br>
              Convergencia de variables aleatorias <br>
              - Convergencia en probabilidad <br>
              - Convergencia en distribución <br>
              - Convergencia en media <br>
              - Convergencia casi segura <br>
              Teorema del límite central
header-includes:
   - \usepackage{amsmath,amssymb,amsthm,amsfonts}
   - \usepackage[sectionbib]{natbib}
   - \usepackage[hidelinks]{hyperref}
output:
  md_document:
    variant: markdown_strict+backtick_code_blocks+autolink_bare_uris+ascii_identifiers+tex_math_single_backslash
    preserve_yaml: TRUE
always_allow_html: yes   
knit: (function(inputFile, encoding) {
  rmarkdown::render(inputFile, encoding = encoding,
  output_dir = "../../EstadisticaII/_posts/", output_format = "all"  ) })
bibliography: "../../referencias.bib"
csl: "../../apa.csl"
link-citations: yes
---

```{r knitr_init, echo=FALSE, cache=FALSE}
library(knitr)
## Global options
opts_chunk$set(echo=TRUE,
               cache=TRUE,
               prompt=FALSE,
               tidy=TRUE,
               comment=NA,
               message=FALSE,
               warning=FALSE,
               fig.path = paste0("../../EstadisticaII/images/", "Clase04"),
               cache.path = "../../EstadisticaII/cache/",
               cache = FALSE)

```

## Estadísticos de orden
Los estadísticos de orden de una muestra aleatoria `$X_{1}, X_{2}, \ldots, X_{n}$` son los valores muestrales puestos en orden ascendente, los cuales se denotan como `$X_{(1)}, X_{(2)}, \ldots, X_{(n)}$` tal que `$X_{(1)} \leq X_{(2)} \leq \ldots \leq X_{(n)}$`.

Ahora si `$X_{(1)}, X_{(2)}, \ldots, X_{(n)}$` son los estadísticos de orden de una muestra aleatoria `$X_{1}, X_{2}, \ldots, X_{n}$` de una población continua con función de densidad de probabilidad `$f(x)$` y función de distribución acumulada `$F(x)$`, entonces la función de densidad de probabilidad del j-ésimo estadístico de orden `$x_{(j)}$` está dada por
`\begin{align*}
f_{j}(x_j) = \frac{n!}{(j-1)!(n-j)!} f(x_j) [F(x_j)]^{j-1}[1-F(x_j)]^{n-j} \quad \text{ para } -\infty < x_j < \infty
\end{align*}`

<button id="Show1" class="btn btn-secondary">Mostrar Ejercicio </button>
<button id="Hide1" class="btn btn-info">Ocultar Ejercicio </button>
<main id="botoncito1"> 
<h3 data-toc-skip> Ejercicio </h3> 
<p>Sea $X_1, X_2, \ldots, X_8$ una muestra aleatoria iid de una distribución uniforme continua, definida en el intervalo $(0,4)$ tal que
$$\begin{align*}
f(x) = \frac{1}{4} \quad \text{ para } 0\leq x \leq 4
\end{align*}$$

Encuentre la función de densidad para el séptimo estadístico de orden, y con éste calcule la probabilidad de que el valor de este estadístico de orden sea lo más de $3.2$. </p>

<h3 data-toc-skip> Solución </h3> 
<p> Con el fin de encontrar la función de densidad del séptimo estadístico de prueba, es necesario encontrar primero la función de distribución acumulada de la distribución uniforme definida en el intervalo $(0,4)$, tal que
$$\begin{align*}
F(x) &= \int_{0}^x f(t) dt\\
     &= \int_{0}^x\frac{1}{4} dt\\
     &= \frac{t}{4} \Bigg|_{0}^x\\
     &= \frac{x}{4} \quad \text{ para } 0 \leq x \leq 4
\end{align*}$$

Conocido el tamaño de la muestra $n = 8$, la función de densidad de probabilidad y la función de distribución acumulada de la distribución uniforme continua definida en el intervalo $(0,4)$, se procede al cálculo de la función de probabilidad del séptimo estadístico de orden $(j=7)$, tal que

$$\begin{align*}
f_{7}(x_7) &= \frac{8!}{(7-1)!(8-7)!} f(x_7) [F(x_7)]^{7-1}[1-F(x_7)]^{8-7} \\
               &= 56 \left(\frac{1}{4}\right) \left[\frac{x_7}{4}\right]^{6}\left[1-\frac{x_7}{4}\right]^{1}\\ 
               &= 56 \left(\frac{1}{4}\right)^8x_7^6\left(4-x_7\right)\\                &= \frac{7}{8192}x_7^6\left(4-x_7\right) \quad \text{ para } \quad 0 < x_7 < 4 \\ 
\end{align*}$$

Y ya con esta función de probabilidad se procede a realizar el cálculo de la la probabilidad del séptimo estadístico de orden sea a lo más de $3.2$, tal que
$$\begin{align*}
\mathbb{P}(x_7 \leq 3.2) &= \int_{0}^{3.2} f_{7}(x_7) dx_7\\
                         &= \int_{0}^{3.2} \frac{7}{8192}x_7^6\left(4-x_7\right) dx_7\\
                         &= \frac{7}{8192} \left(\frac{4x_7^7}{7} - \frac{x_7^8}{8}\right) \Bigg|_{0}^{3.2} \\
                         &=\frac{7}{8192} \left(\frac{4(3.2 - 0)^7}{7} - \frac{(3.2 - 0)^8}{8}\right) \\
                         &=\frac{7}{8192} \left(\frac{4(3.2)^7}{7} - \frac{(3.2)^8}{8}\right) \\
                         &= 0.50331648 \\
\end{align*}$$

Y por tanto se tendrá una probabilidad del $50.33\%$ de que el séptimo estadístico de prueba de una variable aleatoria uniforme definida en el intervalo $(0,4)$ sea a lo más de $3.2$.
</p>
</main>

## Convergencia de variables aleatorias
El término convergencia hace referencia a que a medida que el tamaño de una secuencia de variables aleatorias `$X_1, X_2, X_3, \ldots$` es más y más grande, se espera que el valor de `$X_n$` se acerque cada vez más a una variable aleatoria `$X$` a medida que `$n\to\infty$`

**Para entender el concepto de convergencia**, suponga una variable aleatoria desconocida `$X$` la cual deseamos conocer su valor. Como la variable aleatoria no puede observarse directamente, se decide realizar algún tipo de medición y obtener una estimación de `$X$` la cual podemos llamar `$X_1$`. Luego se realiza otra medición y se actualiza la estimación que se tenía de `$X$`, la cual llamamos `$X_2$`. Entonces si se continúa este proceso, para obtener las estimaciones `$X_1, X_2, X_3, \ldots$`, se espera entonces que a medida que `$n$` aumenta, la estimación `$X_n$` para `$X$` se acercará cada vez más al valor real, es decir, se espera que `$X_n$` converja a `$X$` cuando `$n\to\infty$`.

Aunque el supuesto de que el tamaño de una muestra se acerque a infinito es un supuesto poco realista y se usa meramente como un concepto teórico, a menudo este tipo de supuestos puede proporcionar algunas aproximaciones útiles para el caso en el cual la muestra sea finita, ya que las expresiones suelen simplificarse en el límite.

Existen varios tipos de convergencia en la teoría de probabilidad, y el objetivo será conocer la forma en que éstos se relacionan unos con otros, debido a que existe una jerarquía entre los tipos de convergencia que hace que algunos tipos sean más fuertes que otros, lo cual genera que una secuencia pueda converger en un sentido pero no otro.

<h4 align="center"> Tipos de Convergencia</h4>
![](../../EstadisticaII/images/TiposdeConvergencia.jpg){ width=100% }

### Convergencia en Distribución
Sea `$X_1, X_2, X_3, \ldots$` una secuencia de variables aleatorias, y sea `$X$` una variable aleatoria definida en el espacio muestral, entonces, si `$F_{X_{n}}$` y `$F_{X}$` son las funciones de distribución acumulada de `$X_n$` y `$X$` respectivamente, se tendrá que `$X_n$` converge en distribución a `$X$`, si
`\begin{align*}
\lim_{n\to\infty} F_{X_{n}}(x) = F_{X}(x)
\end{align*}`
para todos los puntos `$x$` donde `$F_{X}(x)$` está definida. En tal caso se escribirá que `$X_n\stackrel{d}{\to}X$`.

<button id="Show2" class="btn btn-secondary">Mostrar Ejercicio </button>
<button id="Hide2" class="btn btn-info">Ocultar Ejercicio </button>
<main id="botoncito2"> 
<h3 data-toc-skip> Ejercicio </h3> 
<p>Sea $X_2, X_3, x_4, \ldots$ una secuencia de variables aleatorias distribuidas, tal que 
$$\begin{align*}
  F_{X_i}(x)=1-\left(1-\frac{1}{i}\right)^{ix} \text{ para } x>0
\end{align*}$$
muestre que $X_n$ converge a una distribución $Exp(1)$. </p>

<h3 data-toc-skip> Solución </h3> 
<p> Sea $X\sim Exp(1)$, entonces si aplicamos límite a $F_{X_n}(x)$ se tendrá que para $x\geq 0$
$$\begin{align*}
  \lim_{n\to\infty}F_{X_n}(x)&=\lim_{n\to\infty}\left[1-\left(1-\frac{1}{n}\right)^{nx}\right] \\
  &=1-\lim_{n\to\infty}\left(1-\frac{1}{n}\right)^{nx} \\
  &=1-e^{-x} \\
  &=F_{X}(x) \text{ para todo } x
\end{align*}$$
concluyendo que $X_{n}\stackrel{d}{\to}X$.</p>
</main>

<!-- #### Propiedades euler -->
<!-- $$\begin{align*} -->
<!-- &1. \lim_{n\to\infty} \left(1 + \frac{1}{n}\right)^n = e^{1} \\ -->
<!-- &2. \lim_{n\to\infty} \left(1 - \frac{1}{n}\right)^n = e^{-1}\\ -->
<!-- &3. \lim_{n\to\infty} \left(1 + \frac{k}{n}\right)^n = e^{k}\\ -->
<!-- &4. \lim_{n\to\infty} \left(1 + \frac{k}{n+m}\right)^{n+m} = e^{k}\\ -->
<!-- &5. \lim_{n\to\infty} \left(1 + \frac{1}{n}\right)^{nx} = e^{x}\\ -->
<!-- &6. \lim_{n\to\infty} \left(1 + \frac{k}{n}\right)^{nx} = e^{xk}\\ -->
<!-- \end{align*}$$ -->

### Convergencia en Probabilidad
Sea `$X_1, X_2, \ldots$` una secuencia de variables aleatorias, y sea `$X$` una variable aleatoria definida en el espacio muestral, entonces, se tendrá que `$X_1, X_2, \ldots$` convergen en probabilidad a `$X$`, si para todo `$\varepsilon>0$`
`\begin{align*}
\lim_{n\to\infty} \mathbb{P}(|X_n - X| \geq \varepsilon) = 0
\end{align*}`

o equivalentemente
`\begin{align*}
\lim_{n\to\infty} \mathbb{P}(|X_n - X| < \varepsilon) = 1
\end{align*}`

En tal caso se escribirá que `$X_n\stackrel{p}{\to}X$`.

<button id="Show3" class="btn btn-secondary">Mostrar Ejercicio </button>
<button id="Hide3" class="btn btn-info">Ocultar Ejercicio </button>
<main id="botoncito3"> 
<h3 data-toc-skip> Ejercicio </h3> 
<p>Sea $X_1, X_2, \ldots$ una secuencia de variables aleatorias distribuidas exponencialmente de la forma $X_i \sim Exp(\lambda=i)$, entonces demuestre que $X_n \stackrel{p}{\to} 0$, es decir, demuestre que la secuencia $X_1, X_2, \ldots$ converge en probabilidad a la variable aleatoria $X=0$. </p>

<h3 data-toc-skip> Solución </h3> 
<p> Como tenemos que $X_n \sim Exp(\lambda=n)$ y $X_n \geq 0$ entonces
$$\begin{align*}
  \lim_{n\to\infty}\mathbb{P}(|X_n - 0| \geq \varepsilon) &= \lim_{n\to\infty}\mathbb{P}(X_n \geq \varepsilon) \\
  &= \lim_{n\to\infty}e^{-n\varepsilon} \\
  &= 0 \quad \text{ para todo } \varepsilon >0\\
\end{align*}$$
concluyendo que $X_n\stackrel{p}{\to}X$.
</p>
</main>

#### Ley de los grandes números
La ley de los grandes números tiene un papel muy central en la probabilidad y la estadística, puesto que éste establece que si repite un experimento de forma independiente una gran cantidad de veces y promedia el resultado, lo que obtenga debe estar cerca del valor esperado. 

Existen dos versiones principales de la ley de los grandes números, a saber, la ley débiles de los grandes números y la ley fuertes de los grandes números, en donde la diferencia de ambas leyes es principalmente teórica.

#### Teorema: Ley débil de los grandes números
Sea `$X_1, X_2, \ldots, X_n$` una secuencia de variables aleatorias iid con media y varianza finita tal que `$\mathbb{E}(X_i) = \mu<\infty$`, `$Var(X_i) = \sigma^2 <\infty$` entonces para todo `$\varepsilon > 0$` se tendrá que
`\begin{align*}
\lim_{n\to \infty} \mathbb{P}(|\bar{X} - \mu| \geq \varepsilon) =0
\end{align*}`
en donde `$\bar{X}$` representa a la media muestral, con media y varianza dadas por
`\begin{align*}
  \mathbb{E}(\bar{X}) =\mu \quad \quad Var(\bar{X}) = \frac{\sigma^2}{n}
\end{align*}`

En tal caso se escribirá que `$\bar{X}\stackrel{p}{\to}\mu$`.

<button id="Show4" class="btn btn-secondary">Mostrar Ejercicio </button>
<button id="Hide4" class="btn btn-info">Ocultar Ejercicio </button>
<main id="botoncito4"> 
<h3 data-toc-skip> Ejercicio </h3> 
<p>Sea $X_1, X_2, \ldots, X_n$ una secuencia de variables aleatorias iid con media dada por $\mathbb{E}(X_i) = \mu$ y varianza dada por $Var(X_i) = \sigma^2$, demuestre que $\bar{X} \stackrel{p}{\to}\mu$.</p>

<h3 data-toc-skip> Solución </h3> 
<p> Como tenemos que $\bar{X}$ posee una media de $\mathbb{E}(\bar{X}) =\mu$ y una varianza de $Var(\bar{X}) = \frac{\sigma^2}{n}$, entonces se tendrá que para todo $\varepsilon > 0$
$$\begin{align*}
  \mathbb{P}(|\bar{X} - \mu| \geq \varepsilon) &= \mathbb{P}((\bar{X} - \mu)^2 \geq \varepsilon^2) \\
  &\leq \frac{\mathbb{E}[(\bar{X} - \mu)^2]}{\varepsilon^2} \quad \text{ (Por teorema de Chebyshev)} \\
  &\leq \frac{Var(\bar{X})}{\varepsilon^2} \\
  &\leq \frac{\sigma^2}{n\varepsilon^2}
\end{align*}$$
y por tanto al aplicar límite cuando $n\to\infty$ se tendrá que
$$\begin{align*}
  \lim_{n\to\infty}\mathbb{P}(|\bar{X} - \mu| \geq \varepsilon) &\leq \lim_{n\to\infty}\frac{\sigma^2}{n\varepsilon^2} \\
  \lim_{n\to\infty}\mathbb{P}(|\bar{X} - \mu| \geq \varepsilon) &=0 \quad \text{ para todo } \varepsilon>0
\end{align*}$$
concluyendo que $\bar{X}\stackrel{p}{\to} \mu$
</p>
</main>

### Convergencia en Media
Sea `$r\geq 1$` un número fijo, entonces la secuencia de variables aleatorias `$X_1, X_2, X_3, \ldots$` convergen en la `$r$`-ésima media o en la `$L^r$` forma a la variable aleatoria `$X$`, si `$\mathbb{E}(|X_n|^r)<\infty$` y 
`\begin{align*}
\lim_{n\to \infty} \mathbb{E}(|X_n - X|^r) =0
\end{align*}`

En tal caso se escribirá que `$X_n\stackrel{L^r}{\to}X$`. Si `$r=2$` se llama convegencia de media cuadrática y se escribiría `$X_n\stackrel{m.c}{\to}X$`

**Nota:** Si una sucesión de variables aleatorias converge en media de orden `$r$`, entonces también converge en media en ordenes menores a `$r$`.

<button id="Show5" class="btn btn-secondary">Mostrar Ejercicio </button>
<button id="Hide5" class="btn btn-info">Ocultar Ejercicio </button>
<main id="botoncito5"> 
<h3 data-toc-skip> Ejercicio </h3> 
<p>Sea $X_1, X_2, \ldots$ una secuencia de variables aleatorias distribuidas exponencialmente de la forma $X_i\sim Unif(0,\frac{1}{i})$, muestre que $X_{n}\stackrel{L^r}{\to}0$ para cualquier $r\geq1$, es decir, demuestre que la secuencia $X_1, X_2, \ldots$ converge en la `$r$`-ésima media a la variable aleatoria $X=0$</p>

<h3 data-toc-skip> Solución </h3> 
<p> Para demostrar esto, defina la función de probabilidad de $X_{n}$ tal que
$$\begin{align*}
  f_{X_n}(x)= n \text{ para } 0\leq x \leq \frac{1}{n}
\end{align*}$$

entonces se tendrá que
$$\begin{align*}
  \mathbb{E}(|X_n - 0|^r) &= \mathbb{E}(X_n^r)\\
                          &= \int_{0}^{\frac{1}{n}} x^r f_{X_n}(x)\ dx\\
                          &= \int_{0}^{\frac{1}{n}} x^r n\ dx\\
                          &= \frac{1}{(r+1)n^r} \\
\end{align*}$$
y por tanto al aplicar límite cuando $n\to\infty$ se tendrá que
$$\begin{align*}
  \lim_{n\to \infty} \mathbb{E}(|X_n - 0|^r) &= \lim_{n\to \infty} \frac{1}{(r+1)n^r} \\
  &= 0 \quad \text{ para todo }  r\geq 1 \\
\end{align*}$$
concluyendo que $X_n\stackrel{L^r}{\to} 0$
</p>
</main>

### Convergencia Casi Segura
Sea `$X_1, X_2, \ldots$` una secuencia de variables aleatorias definidas en el espacio muestral `$S = \{s_1, s_2,\ldots, s_k\}$`, y sea `$X$` una variable aleatoria definida en el espacio muestral, entonces, se tendrá que `$X_1, X_2, \ldots$` convergen casi seguramente a `$X$`, si para todo `$\varepsilon>0$`
`\begin{align*}
  \mathbb{P}\left(\{s\in S:\lim_{n\to \infty}|X_n(s) - X(s)|^r < \varepsilon\} \right) = 1
\end{align*}`

o equivalentemente 
`\begin{align*}
  \mathbb{P}\left(\{s\in S:\lim_{n\to \infty}X_n(s) = X(s)\}\right) = 1
\end{align*}`

En tal caso se escribirá que `$X_n\stackrel{cs}{\to}X$`.

<button id="Show6" class="btn btn-secondary">Mostrar Ejercicio </button>
<button id="Hide6" class="btn btn-info">Ocultar Ejercicio </button>
<main id="botoncito6"> 
<h3 data-toc-skip> Ejercicio </h3> 
<p>Sea el espacio muestral $S$ definido en el intervalo $[0,1]$ y sea $X_1, X_2, \ldots$ una secuencia de variables aleatorias distribuidas de la forma $X_i(s)=s^{i}$, muestre que $X_{n}\stackrel{cs}{\to}0$, es decir, demuestre que la secuencia $X_1, X_2, \ldots$ converge casi seguramente a la variable aleatoria $X(s)=0$</p>

<h3 data-toc-skip> Solución </h3> 
<p> Para demostrar esto defina un punto muestral fijo $s\in[0,1)$, entonces la secuencia de variables aleatoria $X_n(s)$ tendrá límite igual a
$$\begin{align*}
  \lim_{n\to \infty} X_n(s)=\lim_{n\to \infty} s^{n} = 0
\end{align*}$$
sin embargo, si $s=1$, la secuencia de variables aleatorias $X_n(s)$ tendrá límite igual a
$$\begin{align*}
  \lim_{n\to \infty} X_n(1)=\lim_{n\to \infty} 1^{n} = 1
\end{align*}$$

Lo cual significa que la secuencia de variables aleatorias $X_n$ no convergerá puntualmente a $X$ cuando $s=1$ porque 
$$\begin{align*}
  \lim_{n\to \infty} X_n(1)=1 \neq X(1)=0
\end{align*}$$

Ahora, como la probabilidad puntual para la igualdad de este límite cuando $s=1$ es igual a $0$, 
$$\begin{align*}
  \mathbb{P}\left(\{s=1:\lim_{n\to \infty}X_n(1) = X(1)\}\right) = 0
\end{align*}$$

significa que para $s\in [0,1)$, $X_n(s)$ convergerá casi seguramente a $X(s)$ ya que

$$\begin{align*}
  \mathbb{P}\left(\{s\in[0,1):\lim_{n\to \infty}X_n(s) = X(s)\}\right) = 1
\end{align*}$$
concluyendo que $X_n\stackrel{cs}{\to} 0$
</p>
</main>


#### Teorema: Ley fuerte de los grandes números
Sea `$X_1, X_2, \ldots, X_n$` una secuencia de variables aleatorias iid con media y varianza finita tal que `$\mathbb{E}(X_i) = \mu<\infty$`, `$Var(X_i) = \sigma^2 <\infty$` entonces para todo `$\varepsilon > 0$` se tendrá que
`\begin{align*}
\mathbb{P}\left(\lim_{n\to \infty}|\bar{X} - \mu| < \varepsilon \right) = 1
\end{align*}`
en donde `$\bar{X}$` representa a la media muestral, con media y varianza dadas por
`\begin{align*}
  \mathbb{E}(\bar{X}) =\mu \quad \quad Var(\bar{X}) = \frac{\sigma^2}{n}
\end{align*}`

En tal caso se escribirá que `$\bar{X}\stackrel{cs}{\to}\mu$`.

## Teorema del límite central
Sean `$X_1, X_2, \ldots, X_n$` variables aleatoria *iid* con media `$\mathbb{E}(X_i) = \mu$` y varianza `$Var(X_i)=\sigma^2<\infty$` entonces, si se define a `$\bar{X}$` la media muestral con media `$\mathbb{E}(\bar{X}) =\mu$` y varianza `$Var(\bar{X}) = \frac{\sigma^2}{n}$`, se tendrá que la variable aleatoria normalizada
`\begin{align*}
Z_c = \frac{\bar{X}-\mu}{\sigma/\sqrt{n}} \stackrel{a}{\sim} N(0,1)
\end{align*}`
convergerá en distribución a una variable aleatoria normal estándar cuando `$n\to \infty$` (usualmente, se usa como valor de referencia a `$n\geq 30$`).

<button id="Show8" class="btn btn-secondary">Mostrar Ejercicio </button>
<button id="Hide8" class="btn btn-info">Ocultar Ejercicio </button>
<main id="botoncito8"> 
<h3 data-toc-skip> Ejercicio </h3> 
<p>Suponga que Postobon desarrolla una nueva máquina de bebidas para servir de forma automática gaseosas en los cines, de tal forma que la cantidad servida, en mililitros, se distribuya Weibull con parámetro de forma $\alpha = 1/5$ y parámetro de escala $\beta = 3$.<br>
<br>
Entonces, si se decide tomar una muestra aleatoria de $40$ vasos de gaseosa servidos por una de las nuevas máquinas de bebidas, cuál es la probabilidad de que la cantidad promedio de bebida obtenida sea como máximo de $340_{ml}$?.
</p>

<h3 data-toc-skip> Solución </h3> 
<p>En este caso tenemos que la cantidad servida de gaseosa por la nueva máquina no se distribuye normalmente, si no que tiene una distribución Weibull, con parámetros $\alpha = 1/5$ y $\beta = 3$. Adicionalmente, nos piden calcular la probabilidad de que una muestra de $40$ vasos de gaseosa se obtenga como máximo un promedio muestral de $340_{ml}$, es decir
$$\begin{align*}
\mathbb{P}(\bar{X} \leq 340)
\end{align*}$$

Entonces, dado que los datos no se distribuyen normalmente, pero el tamaño de la muestra $n\geq30$, podemos aplicar el teorema del límite central el cual nos dice que, mediante la aplicación de la estandarización 
$$\begin{align*}
Z_c = \frac{\bar{X}-\mu}{\sigma/\sqrt{n}} \stackrel{a}{\sim} N(0,1)
\end{align*}$$
podemos obtener una distribución aproximadamente normal, lo cual nos permitirá realizar el cálculo de la probabilidad de interés.<br>
<br>
Ahora, para poder aplicar la estandarización, debemos calcular primero el valor de la media y desviación estandar poblacionales, y para ello empleamos podemos emplear la definición de esperanza matemática y varianza de la distribución Weibull, tal que la media poblacional será igual a
$$\begin{align*}
\mathbb{E}(X) = \mu = &= \beta\;\Gamma\left(1 + \frac{1}{\alpha}\right)\\
                      &= 3 \Gamma\left(1 + \frac{1}{(1/5)}\right) \\
                      &= 3 \Gamma\left(1 + 5\right) \\
                      &= 3 \Gamma\left(6\right) \\
                      &= 3 (6-1)!\\
                      &= 3 (120) \\
                      &= 360
\end{align*}$$
mientras que, la varianza poblacional será igual a
$$\begin{align*}
Var(X) = \sigma^2 &= \beta^2\left[\Gamma\left(1 + \frac{2}{\alpha}\right) - \Gamma\left(1 + \frac{1}{\alpha}\right)^2\right] \\
                  &= 3^2\left[\Gamma\left(1 + \frac{2}{(1/5)}\right) - \Gamma\left(1 + \frac{1}{(1/5)}\right)^2\right] \\
                  &= 9\left[\Gamma\left(1 + 10\right) - \Gamma\left(1 + 5\right)^2\right] \\
                  &= 9\left[\Gamma\left(11\right) - \Gamma\left(6\right)^2\right] \\
                  &= 9\left[(11 - 1)! - ((6 - 1)!)^2\right] \\
                  &= 9\left[3628800 - (120)^2\right] \\
                  &= 9\left[3628800 - 14400\right] \\
                  &= 9\left[3628800 - 14400\right] \\
                  &= 9\left[3614400\right] \\
                  &= 32529600
\end{align*}$$
es decir que, la desviación estándar poblacional será igual a 
$$\begin{align*}
Sd(X) = \sigma &= \sqrt{Var(X)} \\
               &= \sqrt{32529600} \\
               &= 5703.473
\end{align*}$$

Ahora, con los valores ya calculados para $\mu=360$ y $\sigma=5703.473$, se realiza la estandarización de la probabilidad, para poder realizar su cálculo, tal que
$$\begin{align*}
\mathbb{P}(\bar{X} \leq 340) &= \mathbb{P}(\bar{X} - \mu \leq 340 - 360)\\
                             &= \mathbb{P}\left(\frac{\bar{X} - \mu}{\sigma / \sqrt{n}} \leq \frac{340 - 360}{5703.473/\sqrt{40}}\right)\\
                             &= \mathbb{P}\left(Z \leq -0.02217791\right)\\
\end{align*}$$

Y como $Z \stackrel{a}{\sim} N(0,1)$, podemos encontrar la probabilidad de interés, empleando la <a href="https://github.com/jiperezga/jiperezga.github.io/raw/master/Dataset/Documentos/DistNormEst.pdf">Tabla de la Distribución Normal Estándar</a>, la función <tt>pnorm()</tt> del software <tt>R</tt> o la función <tt>DISTR.NORM.ESTAND.N()</tt> de Excel, tal que
$$\begin{align*}
\mathbb{P}\left(Z \leq -0.02217791\right) = 0.491153
\end{align*}$$

lo cual, dada la equivalencia de la igualdad anterior, significará que
$$\begin{align*}
\mathbb{P}(\bar{X} \leq 340) = 0.491153
\end{align*}$$

es decir que la probabilidad de que la cantidad promedio de bebida obtenida en la muestra de $40$ vasos sea como máximo de $340_{ml}$ es de $49.11\%$.
</p>
</main>
