---
layout: post
title: "Clase 08"
main-class: 'clase'
permalink: /EstadisticaII/EstII:title.html
tags:

introduction: |
              Método de estimación puntual <br>
              - Método de momentos <br>
              - Método de máxima verosimilitud
              
header-includes:
   - \usepackage{amsmath,amssymb,amsthm,amsfonts}
   - \usepackage[sectionbib]{natbib}
   - \usepackage[hidelinks]{hyperref}
output:
  md_document:
    variant: markdown_strict+backtick_code_blocks+autolink_bare_uris+ascii_identifiers+tex_math_single_backslash
    preserve_yaml: TRUE
always_allow_html: yes   
knit: (function(inputFile, encoding) {
  rmarkdown::render(inputFile, encoding = encoding,
  output_dir = "../../EstadisticaII/_posts/", output_format = "all"  ) })
bibliography: "../../referencias.bib"
csl: "../../apa.csl"
link-citations: yes
---

```{r knitr_init, echo=FALSE, cache=FALSE}
library(knitr)
## Global options
opts_chunk$set(echo=TRUE,
               cache=TRUE,
               prompt=FALSE,
               tidy=TRUE,
               comment=NA,
               message=FALSE,
               warning=FALSE,
               fig.path = paste0("../../EstadisticaII/images/", "Clase08"),
               cache.path = "../../EstadisticaII/cache/",
               cache = FALSE)

```

## Métodos de Estimación Puntual
### Método de momentos
Es un procedimiento que se usa para hallar un estimador para uno o más parámetros poblacionales a partir de los momentos muestrales.

Sea `$X_1, X_2, \ldots, X_n$` una muestra aleatoria de una distribución `$X_i;\theta_1, \theta_2, \ldots \theta_k$`, y sea el `$k$`-ésimo momento alrededor del origen dado por 
`\begin{align*}
  \mu_k' = \mathbb{E}(X^k)
\end{align*}`

y sea el `$k$`-ésimo momento muestral dado por
`\begin{align*}
  m_k' = \frac{1}{n}\sum_{i=1}^{n} y_i^k
\end{align*}`

entonces, los estimadores `$(\hat{\theta}_1, \hat{\theta}_2, \ldots \hat{\theta}_k)$` para `$(\theta_1, \theta_2, \ldots \theta_k)$` se obtiene al igualas los correspondientes momentos poblacionales y muestrales para despejar los estimadores deseados.

<button id="Show1" class="btn btn-secondary">Mostrar Ejercicio </button>
<button id="Hide1" class="btn btn-info">Ocultar Ejercicio </button>
<main id="botoncito1"> 
<h3 data-toc-skip> Ejercicio </h3> 
<p> PENDIENTE! >:c</p>

<h3 data-toc-skip> Solución </h3> 
<p> PENDIENTE! :D
</p>
</main>

### Método de máxima verosimilitud
Sea `$X_1, X_2, \ldots, X_n$` una muestra aleatoria iid de una distribución `$f(x; \theta_1, \theta_2, \ldots, \theta_k)$`, con función de verosimilitud dada por

`\begin{align*}
  L(\theta|x_i) &= L(\theta_1, \theta_2, \ldots, \theta_k| X_1, X_2, \ldots, X_k)\\
                &= \prod_{i=1}^{n} f(x_i, \theta_1, \theta_2, \ldots, \theta_k)
\end{align*}`

Entonces el estimador de máxima verosimilitud de `$\hat{\theta}_{MV}$` para el parámetro `$\theta$`, es el valor que maximiza `$L(\theta| x_i)$`, es decir, 

`\begin{align*}
  L(\hat{\theta}_{MV}| X_1, X_2, \ldots, X_k) = \max_{\theta} L(\theta_1, \theta_2, \ldots, \theta_k| X_1, X_2, \ldots, X_k)
\end{align*}`

#### Observación
Cómo `$L(\theta| X)$` es el producto de `$n$` funciones, es recomendable usar la función monótona creciente `$Ln(\cdot)$` antes de maximizar `$L(\theta|X)$`, debido a que es más sencillo hallar la derivada de `$\ell(\theta|X)=Ln(L(\theta|X))$` que hallar la derivada de la multiplicación de `$n$` funciones.

<button id="Show2" class="btn btn-secondary">Mostrar Ejercicio </button>
<button id="Hide2" class="btn btn-info">Ocultar Ejercicio </button>
<main id="botoncito2"> 
<h3 data-toc-skip> Ejercicio </h3> 
<p> PENDIENTE! >:c</p>

<h3 data-toc-skip> Solución </h3> 
<p> PENDIENTE! :D
</p>
</main>