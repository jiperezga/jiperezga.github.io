---
layout: post
title: "Clase 12"
main-class: 'clase'
permalink: /ProbabilidadeInferencia/PeIE:title.html
tags:

introduction: |
  Introducción a la inferencia estadística. <br/>
  Estadísticos. <br/>
  Distribuciones muestrales: <br/>
  - Distribución muestral para la media muestral. <br/>
  - Teorema del Límite Central. <br/>
  - Distribución muestral para proporciones. <br/>
  - Distribución muestral chi-cuadrado.
header-includes:
   - \usepackage{amsmath,amssymb,amsthm,amsfonts}
   - \usepackage[sectionbib]{natbib}
   - \usepackage[hidelinks]{hyperref}
output:
  md_document:
    variant: markdown_strict+backtick_code_blocks+autolink_bare_uris+ascii_identifiers+tex_math_single_backslash
    preserve_yaml: TRUE
always_allow_html: yes   
knit: (function(inputFile, encoding) {
  rmarkdown::render(inputFile, encoding = encoding,
  output_dir = "../../ProbabilidadeInferencia/_posts/", output_format = "all")})
bibliography: "../../referencias.bib"
csl: "../../apa.csl"
---

```{r knitr_init, echo=FALSE, cache=FALSE}
library(knitr)
## Global options
opts_chunk$set(echo=TRUE,
               cache=TRUE,
               prompt=FALSE,
               tidy=TRUE,
               comment=NA,
               message=FALSE,
               warning=FALSE,
               fig.path = paste0("../../ProbabilidadeInferencia/images/", "Clase12"),
               cache.path = "../../ProbabilidadeInferencia/cache/",
               cache = FALSE)

```

## Inferencia estadística
La inferencia estadística es la obtención de conclusiones basadas en datos experimentales. Para entender la naturaleza de la inferencia estadística, se debe entender primero la diferencia entre "población" y "muestra".

**Población:** Consta del total de observaciones del suceso o proceso en que estamos interesados. En muchas ocasiones, no es posible obtener o replicar dicha información.

**Muestra:** Es un subconjunto de la población de interés, extraída con el objetivo de hacer inferencia sobre la población.

**Muestra aleatoria:** Es un subconjunto de la población seleccionado de forma independiente e idénticamente distribuidos (*iid* en adelante).

## Estadístico
Son funciones de las variables aleatorias obtenidas a partir de muestras aleatorias, que tienen por objetivo estimar o hacer inferencia acerca de parámetros desconocidos de una población.

A continuación se definirán algunos estadísticos importantes que sirven para medir el centro y la dispersión de un conjunto de datos, acomodados por orden de magnitud.

## Estadísticos muestrales
Sea `$X_1, X_2, \ldots, Xn$` una muestra aleatoria *iid* de tamaño `$n$`, entonces se tendrán los siguientes estadísticos muestrales

### Media muestral
Es el promedio aritmético del total de las `$n$` observaciones pertenecientes a una muestra aleatoria. Éste estadístico se define como
`\begin{align*}
  \bar{X}=\sum_{i=1}^n\frac{x_i}{n}=\frac{x_1+x_2+\ldots+x_n}{n}
\end{align*}`

En <tt>R</tt>, puede calcularse el valor de la media muestral de una muestra aleatoria mediante la función `mean(datos)`.

### Varianza muestral
Es la distancia media **al cuadrado** del conjunto de observaciones pertenecientes a una muestra aleatoria, respecto a la media muestra.
`\begin{align*}
  S^2=\frac{1}{n-1}\sum_{i=1}^n{(x_i-\bar{X})^2}
\end{align*}` 

siendo el valor `$n-1$` conocido como la corrección de Bessel, el cuál se usa en lugar de la división sobre `$n$` con el fin de corregir el sesgo tendría el estimador.

En <tt>R</tt> puede calcularse la varianza muestral de una muestra aleatoria mediante la función `var(datos)`.

### Desviación estándar muestral
Es la raíz cuadrada de la distancia media **al cuadrado** del conjunto de observaciones pertenecientes a una muestra aleatoria, respeto a la media, es decir, indica qué tan dispersos se encuentra el conjunto de observaciones de una muestra aleatoria respecto a su valor promedio.
`\begin{align*}
  S=\sqrt{S^2}
\end{align*}`

En <tt>R</tt> puede calcularse la desviación estándar de una muestra aleatoria mediante la función `sd(datos)`.

## Distribuciones muestrales
Debido a que todos los estadístico son funciones de las variables aleatorias observadas en una muestra, éstos también serán variables aleatorias que tendrán distribuciones de probabilidad asociadas, distribuciones que son llamadas distribuciones muestrales.

### Distribución muestral de `$\bar{X}$`
Sea `$X_1, X_2, \ldots, X_n$` una muestra aleatoria de tamaño `$n$` de una distribución normal con media `$\mu$` y varianza `$\sigma^2$`, entonces se puede mostrar que
`\begin{align*}
\bar{X}=\frac{1}{n}\sum_{i=1}^n \sim N(\mu, \sigma^2/n)
\end{align*}`
se distribuye normalmente con media `$mu$` y varianza `$\sigma^2/n$`.

#### Teorema
Dado que `$\bar{X}\sim N(\mu,\sigma^2/n)$`, entonces se puede aplicar la estandarización que se emplea a la distribución normal para llevar ésta, a una distribución normal estándar. Dicha estandarización sería de la forma
`\begin{align*}
Z = \frac{\bar{X}-\mu}{\sigma/\sqrt{n}} \sim N(0,1)
\end{align*}`
y se tendrá que `$Z$` se distribuirá como una normal estándar de forma exacta.

### Teorema del límite central
Sea `$X_1, X_2, \ldots, X_n$` una muestra aleatoria *iid* con media `$\mathbb{E}(X_i) = \mu$` y varianza `$Var(X_i)=\sigma^2<\infty$` entonces, cuando `$n\to \infty$`, se tendrá que
`\begin{align*}
Z = \frac{\bar{X}-\mu}{\sigma/\sqrt{n}} \stackrel{a}{\sim} N(0,1)
\end{align*}`
tendrá una distribución aproximadamente normal estándar, cuando `$n\sim \infty$`

### Distribución muestral para proporciones `$p$`
Sea `$X_1, X_2, \ldots, X_n$` una muestra aleatoria *iid* de tamaño `$n$`, tal que `$X\sim b(n,p)$`. Entonces si `$n$` es suficientemente grande, y la proporción `$p$` no está muy cercana a `$0$`o a `$1$`, tal que `$np$` y `$n(1-p)>5$`, entonces se puede probar que
`\begin{align*}
\hat{p}  = \frac{x}{n} \stackrel{a}{\sim} N\left(p, \frac{p(1-p)}{n}\right)
\end{align*}`
donde por teorema de estandarización se obtendrá que
`\begin{align*}
Z = \frac{\hat{p}-p}{\sqrt{\frac{p(1-p)}{n}}} \stackrel{a}{\sim} N(0,1)
\end{align*}`

### Distribución de una combinación lineal
Sean `$X_1$` y `$X_2$` dos variables aleatorias normalmente distribuidas con media `$\mu$` y varianza `$\sigma^2$`. Y si `$Y$` es una combinación lineal de `$X_1$` y `$X_2$`, tal que
`\begin{align*}
Y = X_1 + X_2
\end{align*}`
entonces, la media de `$Y$` estará dada por
`\begin{align*}
\mathbb{E}(Y) = \mu_1 + \mu_2
\end{align*}`

y la varianza de `$Y$` estará dada por
`\begin{align*}
Var(Y) = \sigma_{x_1}^2 + \sigma_{x_2}^2 + 2 \sigma_{x_1x_2}
\end{align*}`

o en caso de que `$X_1$` y `$X_2$` sean variables aleatorias independientes, entonces se tendrá que la varianza de `$Y$` estará dada por
`\begin{align*}
Var(Y) = \sigma_{x_1}^2 + \sigma_{x_2}^2
\end{align*}`

### Teorema
Sea `$X_1, X_2, \ldots, X_n$` una muestra aleatoria *iid* de una distribución `$N(\mu,\sigma^2)$` de tamaño `$n$`, entonces `$Z_i = (x_i - \mu)/\sigma$`, para `$i =1,2,\ldots,n$` serán una variables aleatorias normales estándar independientes, y 
`\begin{align*}
\sum_{i=1}^n Z_i^2 = \sum_{i=1}^n\left(\frac{x_i-\mu}{\sigma}\right)^2 \sim \chi^2_n
\end{align*}`
tiene una distribución chi-cuadrado con `$n$` grados de libertad.

### Teorema
Si `$X\sim \chi^2_\nu$` entonces se puede probar que la media y varianza de la variable aleatoria `$X$` están dadas por
`\begin{align*}
\mathbb{E}(X)=\nu \quad \quad Var(X)=2\nu
\end{align*}`

### Distribución muestral `$\chi^2$`
Sea `$X_1, X_2, \ldots, X_n$` una muestra aleatoria *iid* de una distribución `$N(\mu,\sigma^2)$` de tamaño `$n$`, entonces se tendrá qué
`\begin{align*}
\chi^2_c = \frac{(n-1)S^2}{\sigma^2} \sim \chi^2_{n-1}
\end{align*}`
tiene una distribución chi-cuadrado con `$n-1$` grados de libertad.

#### Propiedades
Si `$X_1, X_2, \ldots, X_n$` una muestra aleatoria *iid* de una distribución `$N(\mu,\sigma^2)$` de tamaño `$n$`, y se tiene que `$\bar{X}$` y `$S^2$` son la media y varianza muestrales, entonces

1. Las variables aleatorias `$\bar{X}$` y `$S^2$` son independientes.
2. la esperanza y la varianza de la variable aleatoria `$S^2$` estarán dadas por
`\begin{align*}
\mathbb{E}(S^2)= \sigma^2 \quad \text{ y } \quad Var(S^2) = \frac{2(\sigma^2)^2}{n-1}
\end{align*}`