---
layout: post
title: "Clase 13"
main-class: 'clase'
permalink: /ProbabilidadeInferencia/PeIE:title.html
tags:

introduction: |
  Distribuciones muestrales: <br/>
  - Distribución muestral para proporciones. <br/>
  - Distribución muestral chi-cuadrado.
header-includes:
   - \usepackage{amsmath,amssymb,amsthm,amsfonts}
   - \usepackage[sectionbib]{natbib}
   - \usepackage[hidelinks]{hyperref}
output:
  md_document:
    variant: markdown_strict+backtick_code_blocks+autolink_bare_uris+ascii_identifiers+tex_math_single_backslash
    preserve_yaml: TRUE
always_allow_html: yes   
knit: (function(inputFile, encoding) {
  rmarkdown::render(inputFile, encoding = encoding,
  output_dir = "../../ProbabilidadeInferencia/_posts/", output_format = "all")})
bibliography: "../../referencias.bib"
csl: "../../apa.csl"
---







Distribuciones muestrales
-------------------------

### Distribución muestral para proporciones `$p$`

Sea `$X_1, X_2, \ldots, X_n$` una muestra aleatoria *iid* de tamaño
`$n$`, tal que `$X\sim b(n,p)$`. Entonces si `$n$` es suficientemente
grande, y la proporción `$p$` no está muy cercana a `$0$`o a `$1$`, tal
que `$np$` y `$n(1-p)>5$`, entonces se puede probar que
`\begin{align*} \hat{p}  = \frac{x}{n} \stackrel{a}{\sim} N\left(p, \frac{p(1-p)}{n}\right) \end{align*}`
donde por teorema de estandarización se obtendrá que
`\begin{align*} Z = \frac{\hat{p}-p}{\sqrt{\frac{p(1-p)}{n}}} \stackrel{a}{\sim} N(0,1) \end{align*}`

### Distribución de una combinación lineal

Sean `$X_1$` y `$X_2$` dos variables aleatorias normalmente distribuidas
con media `$\mu$` y varianza `$\sigma^2$`. Y si `$Y$` es una combinación
lineal de `$X_1$` y `$X_2$`, tal que
`\begin{align*} Y = X_1 + X_2 \end{align*}` entonces, la media de `$Y$`
estará dada por
`\begin{align*} \mathbb{E}(Y) = \mu_1 + \mu_2 \end{align*}`

y la varianza de `$Y$` estará dada por
`\begin{align*} Var(Y) = \sigma_{x_1}^2 + \sigma_{x_2}^2 + 2 \sigma_{x_1x_2} \end{align*}`

o en caso de que `$X_1$` y `$X_2$` sean variables aleatorias
independientes, entonces se tendrá que la varianza de `$Y$` estará dada
por
`\begin{align*} Var(Y) = \sigma_{x_1}^2 + \sigma_{x_2}^2 \end{align*}`

### Teorema

Sea `$X_1, X_2, \ldots, X_n$` una muestra aleatoria *iid* de una
distribución `$N(\mu,\sigma^2)$` de tamaño `$n$`, entonces
`$Z_i = (x_i - \mu)/\sigma$`, para `$i =1,2,\ldots,n$` serán una
variables aleatorias normales estándar independientes, y
`\begin{align*} \sum_{i=1}^n Z_i^2 = \sum_{i=1}^n\left(\frac{x_i-\mu}{\sigma}\right)^2 \sim \chi^2_n \end{align*}`
tiene una distribución chi-cuadrado con `$n$` grados de libertad.

### Teorema

Si `$X\sim \chi^2_\nu$` entonces se puede probar que la media y varianza
de la variable aleatoria `$X$` están dadas por
`\begin{align*} \mathbb{E}(X)=\nu \quad \quad Var(X)=2\nu \end{align*}`

### Distribución muestral `$\chi^2$`

Sea `$X_1, X_2, \ldots, X_n$` una muestra aleatoria *iid* de una
distribución `$N(\mu,\sigma^2)$` de tamaño `$n$`, entonces se tendrá qué
`\begin{align*} \chi^2_c = \frac{(n-1)S^2}{\sigma^2} \sim \chi^2_{n-1} \end{align*}`
tiene una distribución chi-cuadrado con `$n-1$` grados de libertad.

#### Propiedades

Si `$X_1, X_2, \ldots, X_n$` una muestra aleatoria *iid* de una
distribución `$N(\mu,\sigma^2)$` de tamaño `$n$`, y se tiene que
`$\bar{X}$` y `$S^2$` son la media y varianza muestrales, entonces

1.  Las variables aleatorias `$\bar{X}$` y `$S^2$` son independientes.
2.  la esperanza y la varianza de la variable aleatoria `$S^2$` estarán
    dadas por
    `\begin{align*} \mathbb{E}(S^2)= \sigma^2 \quad \text{ y } \quad Var(S^2) = \frac{2(\sigma^2)^2}{n-1} \end{align*}`
